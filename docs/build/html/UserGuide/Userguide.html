
<!DOCTYPE html>

<html lang="pt-BR">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Guia do usuário &#8212; documentação Cluster Cin latest</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/groundwork.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/translations.js"></script>
    <link rel="index" title="Índice" href="../genindex.html" />
    <link rel="search" title="Buscar" href="../search.html" />
    <link rel="prev" title="Infraestrutura de computação e políticas" href="../information.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navegação</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="Índice Geral"
             accesskey="I">índice</a></li>
        <li class="right" >
          <a href="../information.html" title="Infraestrutura de computação e políticas"
             accesskey="P">anterior</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">documentação Cluster Cin latest</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Guia do usuário</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="guia-do-usuario">
<span id="userguide"></span><h1>Guia do usuário<a class="headerlink" href="#guia-do-usuario" title="Link permanente para este cabeçalho">¶</a></h1>
<p>…or <em>IDT’s list of opinionated howtos</em></p>
<p>Esta seção busca fornecer aos usuários da infraestrutura Apuana conhecimentos práticos,
dicas e truques e comandos de exemplo.</p>
<section id="executando-o-seu-codigo">
<h2>Executando o seu código<a class="headerlink" href="#executando-o-seu-codigo" title="Link permanente para este cabeçalho">¶</a></h2>
<section id="guia-de-comandos-slurm">
<h3>Guia de comandos SLURM<a class="headerlink" href="#guia-de-comandos-slurm" title="Link permanente para este cabeçalho">¶</a></h3>
<section id="uso-basico">
<h4>Uso básico<a class="headerlink" href="#uso-basico" title="Link permanente para este cabeçalho">¶</a></h4>
<p>A documentação do SLURM <a class="reference external" href="https://slurm.schedmd.com/documentation.html">https://slurm.schedmd.com/documentation.html</a>
fornece informações extensas sobre os comandos disponíveis para consultar o
status do cluster ou enviar trabalhos.</p>
<p>A seguir, são apresentados alguns exemplos básicos de como usar o SLURM.</p>
</section>
<section id="enviando-trabalhos">
<h4>Enviando trabalhos<a class="headerlink" href="#enviando-trabalhos" title="Link permanente para este cabeçalho">¶</a></h4>
<section id="trabalho-em-lote">
<h5>Trabalho em lote<a class="headerlink" href="#trabalho-em-lote" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Para enviar um trabalho em lote, você precisa criar um script contendo o(s) comando(s) principal(is)
que deseja executar nos recursos/nós alocados.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span>!/bin/bash
<span class="gp">#</span>SBATCH<span class="w"> </span>--job-name<span class="o">=</span><span class="nb">test</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--output<span class="o">=</span>job_output.txt
<span class="gp">#</span>SBATCH<span class="w"> </span>--error<span class="o">=</span>job_error.txt
<span class="gp">#</span>SBATCH<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--time<span class="o">=</span><span class="m">10</span>:00
<span class="gp">#</span>SBATCH<span class="w"> </span>--mem<span class="o">=</span>100Gb

<span class="go">module load python/3.5</span>
<span class="go">python my_script.py</span>
</pre></div>
</div>
<p>Seu script de trabalho é então enviado para o SLURM com <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> (<a class="reference external" href="https://slurm.schedmd.com/sbatch.html">ref.</a>)</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sbatch<span class="w"> </span>job_script
<span class="go">sbatch: Submitted batch job 4323674</span>
</pre></div>
</div>
<p>O diretório de trabalho do trabalho será aquele onde você executou o comando <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>.</p>
<div class="admonition tip">
<p class="admonition-title">Dica</p>
<p>As diretivas do Slurm podem ser especificadas na linha de comando juntamente
com <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> ou dentro do script de trabalho com uma linha iniciada por <code class="docutils literal notranslate"><span class="pre">#SBATCH</span></code>.</p>
</div>
</section>
<section id="job-interativo">
<h5>Job interativo<a class="headerlink" href="#job-interativo" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Os gerenciadores de carga geralmente executam trabalhos em lote para evitar ter que monitorar
sua progressão e deixar o agendador executá-lo assim que os recursos estiverem disponíveis.
Se você quiser acessar um shell enquanto utiliza recursos do cluster, pode enviar um trabalho
interativo onde o executável principal é um shell com o comando <code class="docutils literal notranslate"><span class="pre">srun/salloc</span></code>.</p>
<blockquote>
<div><p>(<a class="reference external" href="https://slurm.schedmd.com/srun.html">srun</a>/<a class="reference external" href="https://slurm.schedmd.com/salloc.html">salloc</a>) comandos:</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">salloc</span>
</pre></div>
</div>
<p>Iniciar um trabalho interativo no primeiro nó disponível com os recursos padrão
definidos no SLURM (1 tarefa/1 CPU). O comando  <code class="docutils literal notranslate"><span class="pre">srun</span></code> aceita os mesmos argumentos
que <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>, com exceção do ambiente que não é passado.</p>
<div class="admonition tip">
<p class="admonition-title">Dica</p>
<p>Para passar seu ambiente atual para um trabalho interativo, adicione  <code class="docutils literal notranslate"><span class="pre">--preserve-env</span></code> ao <code class="docutils literal notranslate"><span class="pre">srun</span></code>.</p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">salloc</span></code> também pode ser usado e é principalmente um invólucro em torno de <code class="docutils literal notranslate"><span class="pre">srun</span></code> se
fornecido sem mais informações, mas fornece mais flexibilidade se, por exemplo,
você quiser obter uma alocação em vários nós.</p>
</section>
</section>
<section id="argumentos-de-submissao-de-tarefas">
<h4>Argumentos de submissão de tarefas<a class="headerlink" href="#argumentos-de-submissao-de-tarefas" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Para selecionar com precisão os recursos para sua tarefa, vários argumentos estão disponíveis. Os mais importantes são:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Argumento</p></th>
<th class="head"><p>Descrição</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-n, –ntasks=&lt;number&gt;</p></td>
<td><p>O número de tarefas no seu script, geralmente é 1.</p></td>
</tr>
<tr class="row-odd"><td><p>-c, –cpus-per-task=&lt;ncpus&gt;</p></td>
<td><p>O número de núcleos para cada tarefa.</p></td>
</tr>
<tr class="row-even"><td><p>-t, –time=&lt;time&gt;</p></td>
<td><p>Tempo solicitado para o seu trabalho.</p></td>
</tr>
<tr class="row-odd"><td><p>–mem=&lt;size[units]&gt;</p></td>
<td><p>Memória solicitada para todas as tarefas do seu trabalho.</p></td>
</tr>
<tr class="row-even"><td><p>–gres=&lt;list&gt;</p></td>
<td><p>Selecione recursos genéricos, como GPUs, para o seu trabalho: <code class="docutils literal notranslate"><span class="pre">--gres=gpu:GPU_MODEL</span></code></p></td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Dica</p>
<p>Sempre considere solicitar a quantidade adequada de recursos para melhorar o
agendamento do seu trabalho (trabalhos pequenos sempre são executados primeiro).</p>
</div>
</section>
<section id="verificando-job-status">
<h4>verificando job status<a class="headerlink" href="#verificando-job-status" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Para exibir os <em>jobs</em> atualmente na fila, use <code class="docutils literal notranslate"><span class="pre">squeue</span></code> e para obter apenas seus trabalhos digite squeue -u $USER</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>squeue<span class="w"> </span>-u<span class="w"> </span><span class="nv">$USER</span>
<span class="go">JOBID   USER          NAME    ST  START_TIME         TIME NODES CPUS TRES_PER_NMIN_MEM NODELIST (REASON) COMMENT</span>
<span class="go">133     my_username   myjob   R   2019-03-28T18:33   0:50     1    2        N/A  7000M node1 (None) (null)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>O número máximo de trabalhos que podem ser enviados ao sistema por usuário é 1000 (MaxSubmitJobs=1000)
em qualquer momento da associação dada. Se este limite for atingido, novas solicitações de envio serão
negadas até que os trabalhos existentes nesta associação sejam concluídos.</p>
</div>
</section>
<section id="removendo-um-job">
<h4>Removendo um job<a class="headerlink" href="#removendo-um-job" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Para cancelar o seu trabalho, simplesmente use <code class="docutils literal notranslate"><span class="pre">scancel</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">scancel 4323674</span>
</pre></div>
</div>
</section>
</section>
<section id="particionamento">
<h3>Particionamento<a class="headerlink" href="#particionamento" title="Link permanente para este cabeçalho">¶</a></h3>
<p>Como não temos muitas GPUs no cluster, os recursos devem ser compartilhados de forma justa.
A opção <code class="docutils literal notranslate"><span class="pre">--partition=/-p</span></code> do SLURM permite que você defina a prioridade necessária para um trabalho.
Cada trabalho atribuído com uma prioridade pode interromper trabalhos com prioridade mais baixa:
<code class="docutils literal notranslate"><span class="pre">unkillable</span> <span class="pre">&gt;</span> <span class="pre">main</span> <span class="pre">&gt;</span> <span class="pre">long</span></code>. Uma vez interrompido, seu trabalho é morto sem aviso prévio e é automaticamente
reenfileirado na mesma partição até que os recursos estejam disponíveis. (Para aproveitar um mecanismo de
interrupção diferente, consulte a documentação do SLURM).
<span class="xref std std-ref">Handling preemption</span>)</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Flag</p></th>
<th class="head"><p>Max Resource Usage</p></th>
<th class="head"><p>Max Time</p></th>
<th class="head"><p>Note</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>--partition=unkillable</p></td>
<td><p>6  CPUs, mem=32G,  1 GPU</p></td>
<td><p>2 days</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>--partition=unkillable-cpu</p></td>
<td><p>2  CPUs, mem=16G</p></td>
<td><p>2 days</p></td>
<td><p>CPU-only jobs</p></td>
</tr>
<tr class="row-even"><td><p>--partition=short-unkillable</p></td>
<td><p>24 CPUs, mem=128G, 4 GPUs</p></td>
<td><p>3 hours (!)</p></td>
<td><p>Large but short jobs</p></td>
</tr>
<tr class="row-odd"><td><p>--partition=main</p></td>
<td><p>8  CPUs, mem=48G,  2 GPUs</p></td>
<td><p>5 days</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>--partition=main-cpu</p></td>
<td><p>8  CPUs, mem=64G</p></td>
<td><p>5 days</p></td>
<td><p>CPU-only jobs</p></td>
</tr>
<tr class="row-odd"><td><p>--partition=long</p></td>
<td><p>no limit of resources</p></td>
<td><p>7 days</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>--partition=long-cpu</p></td>
<td><p>no limit of resources</p></td>
<td><p>7 days</p></td>
<td><p>CPU-only jobs</p></td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="admonition-title">Aviso</p>
<p>Historicamente, antes da introdução em 2022 de nós exclusivos para CPU
(por exemplo, a série “cn-f”), trabalhos apenas com CPU eram executados lado
a lado com trabalhos com GPU em nós de GPU. Para evitar que esses trabalhos
obstruíssem qualquer trabalho com GPU, eles sempre tinham a menor prioridade
e eram preemptíveis. Isso foi implementado automaticamente atribuindo-os a uma
das partições agora obsoletas <code class="docutils literal notranslate"><span class="pre">cpu_jobs</span></code>, <code class="docutils literal notranslate"><span class="pre">cpu_jobs_low</span></code> ou <code class="docutils literal notranslate"><span class="pre">cpu_jobs_low-grace</span></code>.
Não use mais esses nomes de partição. Prefira os nomes de partição <code class="docutils literal notranslate"><span class="pre">*-cpu</span></code> definidos acima.</p>
<p>Para fins de compatibilidade com versões anteriores, os nomes das partições legadas são traduzidos
para seu equivalente efetivo <code class="docutils literal notranslate"><span class="pre">long-cpu</span></code>, mas eventualmente serão removidos completamente.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Como conveniência, se você solicitar a partição <code class="docutils literal notranslate"><span class="pre">unkillable</span></code>, <code class="docutils literal notranslate"><span class="pre">main</span></code> ou <code class="docutils literal notranslate"><span class="pre">long</span></code> para um trabalho
apenas com CPU, a partição será traduzida automaticamente para seu equivalente <code class="docutils literal notranslate"><span class="pre">-cpu</span></code>.</p>
</div>
</section>
</section>
<section id="preocupacoes-e-solucoes-de-portabilidade">
<h2>Preocupações e soluções de portabilidade<a class="headerlink" href="#preocupacoes-e-solucoes-de-portabilidade" title="Link permanente para este cabeçalho">¶</a></h2>
<p>Ao trabalhar em um projeto de software, é importante estar ciente
de todo o software e bibliotecas nos quais o projeto depende e
listá-los explicitamente e sob um sistema de controle de versão
de tal forma que possam ser facilmente instalados e disponibilizados
em diferentes sistemas. As vantagens são significativas:</p>
<ul class="simple">
<li><p>Facilidade de instalação e execução no cluster</p></li>
<li><p>Facilidade de colaboração</p></li>
<li><p>Melhor reprodutibilidade</p></li>
</ul>
<p>Para alcançar isso, tente sempre manter em mente os seguintes aspectos:</p>
<ul class="simple">
<li><dl class="simple">
<dt>Versões: Para cada dependência, certifique-se de ter algum registro da versão</dt><dd><p>específica que está usando durante o desenvolvimento. Dessa forma, no futuro, você
poderá reproduzir o ambiente original que sabe ser compatível. De fato, quanto mais
tempo passa, mais provável é que novas versões de alguma dependência tenham alterações
quebradas. O comando pip freeze pode criar tal registro para dependências do Python.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Isolamento: Idealmente, cada um de seus projetos de software deve estar isolado dos outros.</dt><dd><p>O que isso significa é que atualizar o ambiente do projeto A não deve atualizar o ambiente do
projeto B. Dessa forma, você pode instalar e atualizar software e bibliotecas livremente para
o primeiro, sem se preocupar em quebrar o segundo (o que você pode não perceber até semanas
depois, na próxima vez em que trabalhar no projeto B!) O isolamento pode ser alcançado usando
<span class="xref std std-ref">Python Virtual environments</span> and <span class="xref std std-ref">containers</span>.</p>
</dd>
</dl>
</li>
</ul>
<section id="gerenciando-seus-ambientes">
<h3>Gerenciando seus ambientes<a class="headerlink" href="#gerenciando-seus-ambientes" title="Link permanente para este cabeçalho">¶</a></h3>
</section>
<section id="ambientes-virtuais">
<span id="python"></span><h3>Ambientes virtuais<a class="headerlink" href="#ambientes-virtuais" title="Link permanente para este cabeçalho">¶</a></h3>
<p>Um ambiente virtual em Python é um ambiente local e isolado no qual você pode instalar
ou desinstalar pacotes do Python sem interferir no ambiente global (ou em outros ambientes virtuais).
Ele geralmente fica em um diretório (a localização varia dependendo se você usa venv, conda ou poetry).
Para usar um ambiente virtual, você precisa ativá-lo. Ativar um ambiente define essencialmente variáveis
de ambiente em seu shell para que:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">python</span></code> aponta para a versão correta do Python para aquele ambiente (diferentes ambientes virtuais podem usar</p></li>
</ul>
<blockquote>
<div><p>diferentes versões do Python!)</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">python</span></code> procura pacotes no ambiente virtual</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span></code> instala pacotes no ambiente virtual</p></li>
<li><p>Quaisquer comandos de shell instalados via <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span></code> estão disponíveis</p></li>
</ul>
<p>Para executar experimentos dentro de um ambiente virtual, você pode simplesmente ativá-lo no script fornecido para <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>.</p>
<section id="pip-virtualenv">
<h4>Pip/Virtualenv<a class="headerlink" href="#pip-virtualenv" title="Link permanente para este cabeçalho">¶</a></h4>
<p>O Pip é o gerenciador de pacotes preferido para Python e cada cluster fornece
diversas versões do Python por meio do módulo associado, que vem com o pip.
Para instalar novos pacotes, você primeiro precisará criar um espaço pessoal
para que eles possam ser armazenados. A solução preferida (assim como é nos
clusters da Digital Research Alliance do Canadá) é usar ambientes virtuais.</p>
<blockquote>
<div><p><a class="reference external" href="https://virtualenv.pypa.io/en/stable/">https://virtualenv.pypa.io/en/stable/</a>.</p>
</div></blockquote>
<p>Primeiro, carregue o módulo Python que você deseja usar:
.. code-block:: console</p>
<blockquote>
<div><p>module load python/3.8</p>
</div></blockquote>
<p>Então, crie um ambiente virtual no seu diretório <code class="docutils literal notranslate"><span class="pre">home</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">python -m venv $HOME/&lt;env&gt;</span>
</pre></div>
</div>
<p>onde <code class="docutils literal notranslate"><span class="pre">&lt;env&gt;</span></code> é o nome do seu ambiente. Finalmente, ative o ambiente:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">source $HOME/&lt;env&gt;/bin/activate</span>
</pre></div>
</div>
<p>Agora você pode instalar qualquer pacote Python que desejar usando o comando <code class="docutils literal notranslate"><span class="pre">pip</span></code>, por exemplo:
<a class="reference external" href="https://pytorch.org/get-started/locally">pytorch</a>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pip install torch torchvision</span>
</pre></div>
</div>
<p>Or <a class="reference external" href="https://www.tensorflow.org/install/gpu">Tensorflow</a>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pip install tensorflow-gpu</span>
</pre></div>
</div>
</section>
<section id="conda">
<h4>Conda<a class="headerlink" href="#conda" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Outra solução para Python é usar o miniconda.
<a class="reference external" href="https://docs.conda.io/en/latest/miniconda.html">https://docs.conda.io/en/latest/miniconda.html</a> ou anaconda
<a class="reference external" href="https://docs.anaconda.com">https://docs.anaconda.com</a></p>
</section>
</section>
<section id="usando-modulos">
<h3>Usando módulos<a class="headerlink" href="#usando-modulos" title="Link permanente para este cabeçalho">¶</a></h3>
<p>Muito software, como Python e Conda, já está compilado e disponível no cluster por
meio do comando <code class="docutils literal notranslate"><span class="pre">module</span></code> e seus subcomandos. Em particular, se você deseja usar
o <code class="docutils literal notranslate"><span class="pre">Python</span> <span class="pre">3.7</span></code>, basta fazer:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">module load python/3.7</span>
</pre></div>
</div>
</section>
<section id="no-uso-de-conteineres">
<h3>No uso de contêineres<a class="headerlink" href="#no-uso-de-conteineres" title="Link permanente para este cabeçalho">¶</a></h3>
<p>Outra opção para criar código portátil é: <a class="reference internal" href="Userguide_singularity.html#using-containers"><span class="std std-ref">Usando Conteiners no cluster</span></a>.</p>
<dl class="simple">
<dt>Containers são uma abordagem popular para implantar aplicativos, empacotando juntos muitas das dependências necessárias.</dt><dd><p>A ferramenta mais popular para isso é o <a class="reference external" href="https://www.docker.com/">Docker</a>.</p>
</dd>
</dl>
</section>
</section>
<section id="singularity">
<h2>Singularity<a class="headerlink" href="#singularity" title="Link permanente para este cabeçalho">¶</a></h2>
<section id="visao-geral">
<h3>Visão Geral<a class="headerlink" href="#visao-geral" title="Link permanente para este cabeçalho">¶</a></h3>
<section id="o-que-e-singularidade">
<h4>O que é singularidade<a class="headerlink" href="#o-que-e-singularidade" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Executar o Docker no SLURM é um problema de segurança (por exemplo, executando como root,
tendo a capacidade de montar qualquer diretório). A alternativa é usar o Singularity,
que é uma solução popular no mundo de HPC.</p>
<p>Existe um bom nível de compatibilidade entre Docker e Singularity, e podemos encontrar
muitas alegações exageradas sobre a capacidade de converter contêineres do Docker para
Singularity sem qualquer atrito. Muitas vezes, imagens do DockerHub são 100% compatíveis
com o Singularity e podem ser usadas sem atrito, mas as coisas ficam complicadas quando
tentamos converter nossos próprios arquivos de construção do Docker em receitas do Singularity.</p>
</section>
<section id="links-para-documentacao-oficial">
<h4>Links para documentação oficial<a class="headerlink" href="#links-para-documentacao-oficial" title="Link permanente para este cabeçalho">¶</a></h4>
<ul class="simple">
<li><p>official <a class="reference external" href="https://singularity-docs.readthedocs.io/en/latest/">Singularity user guide</a></p></li>
<li><p>official <a class="reference external" href="https://sylabs.io/guides/latest/admin-guide/">Singularity admin guide</a></p></li>
</ul>
</section>
<section id="visao-gerald-dos-passos-usados-na-pratica">
<h4>Visão gerald dos passos usados na prática<a class="headerlink" href="#visao-gerald-dos-passos-usados-na-pratica" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Na maioria das vezes, o processo para criar e usar um contêiner Singularity é:</p>
<ul class="simple">
<li><p>No seu computador Linux (em casa ou no trabalho)</p>
<ul>
<li><p>selecione uma imagem Docker do DockerHub (por exemplo, <em>pytorch/pytorch</em>)</p></li>
<li><p>crie um arquivo de receita para o Singularity que comece com essa imagem do DockerHub</p></li>
<li><p>construa o arquivo de receita, criando assim o arquivo de imagem (por exemplo, <code class="docutils literal notranslate"><span class="pre">my-pytorch-image.sif</span></code>)</p></li>
<li><p>teste seu contêiner Singularity antes de enviá-lo para o cluster</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rsync</span> <span class="pre">-av</span> <span class="pre">my-pytorch-image.sif</span> <span class="pre">&lt;login-node&gt;:Documents/my-singularity-images</span></code></p></li>
</ul>
</li>
<li><p>No nó de login desse cluster</p>
<ul>
<li><p>enfileire seus trabalhos com <code class="docutils literal notranslate"><span class="pre">sbatch</span> <span class="pre">...</span></code></p></li>
<li><p>(observe que seus trabalhos copiarão o arquivo <code class="docutils literal notranslate"><span class="pre">my-pytorch-image.sif</span></code> para $SLURM_TMPDIR e então iniciarão o Singularity com essa imagem)
faça outra coisa enquanto espera que eles terminem</p></li>
<li><p>enfileire mais trabalhos com o mesmo <code class="docutils literal notranslate"><span class="pre">my-pytorch-image.sif</span></code>, reutilizando-o várias vezes</p></li>
</ul>
</li>
</ul>
<p>Nas próximas seções, você encontrará exemplos específicos ou dicas para realizar na prática as etapas destacadas acima.</p>
</section>
<section id="nao-nao-no-macos">
<h4>Não, não no MacOS<a class="headerlink" href="#nao-nao-no-macos" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Singularity não funciona no MacOS, até a data desta escrita em 2021.
Docker realmente não roda no MacOS, mas o Docker instala silenciosamente uma
máquina virtual executando Linux, o que torna a experiência agradável,
e o usuário não precisa se preocupar com os detalhes de como o Docker faz isso.</p>
<p>Dado sua origem em HPC, o Singularity não fornece esse tipo de experiência sem problemas no MacOS,
embora tecnicamente seja possível executá-lo dentro de uma máquina virtual Linux no MacOS.</p>
</section>
<section id="onde-construir-imagens">
<h4>Onde construir imagens<a class="headerlink" href="#onde-construir-imagens" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Construir imagens do Singularity é uma tarefa bastante pesada, que pode levar 20 minutos
se você tiver muitas etapas na sua receita. Isso torna uma tarefa ruim para rodar em
os nós de login de nossos clusters, especialmente se precisar ser executado regularmente.</p>
<p>No cluster Mila, temos a sorte de ter acesso irrestrito à internet nos nós de computação,
o que significa que qualquer pessoa pode solicitar um nó de CPU interativo (sem necessidade de GPU)
e construir suas imagens lá sem problemas.</p>
<div class="admonition warning">
<p class="admonition-title">Aviso</p>
<p>Não construa imagens do Singularity do zero toda vez que executar um
trabalho em um grande lote. Isso será um desperdício colossal de tempo de GPU e também de
largura de banda da internet. Se você configurar seu fluxo de trabalho corretamente
(por exemplo, usando caminhos de ligação para o seu código e dados), você pode passar meses reutilizando a mesma
imagem do Singularity <code class="docutils literal notranslate"><span class="pre">my-pytorch-image.sif</span></code>.</p>
</div>
</section>
</section>
<section id="construindo-os-containers">
<h3>Construindo os containers<a class="headerlink" href="#construindo-os-containers" title="Link permanente para este cabeçalho">¶</a></h3>
<p>Construir um container é como criar um novo ambiente, exceto que os containers são
muito mais poderosos, pois são sistemas autocontidos. Com o Singularity, existem
duas maneiras de construir containers.</p>
<p>A primeira é fazê-lo você mesmo, é como quando você compra um novo laptop Linux e
não sabe muito bem o que precisa, se perceber que algo está faltando, você o instala.
Aqui, você pode obter um container vanilla com o Ubuntu chamado sandbox, você faz o
login e instala cada pacote por si mesmo. Esse procedimento pode levar tempo, mas permitirá
que você entenda como as coisas funcionam e o que precisa ser feito. Isso é recomendado se
você precisa descobrir como as coisas serão compiladas ou se deseja instalar pacotes na hora
Nos referiremos a este procedimento como singularity sandboxes.</p>
<p>A segunda maneira é mais como se você soubesse o que quer, então você escreve uma lista de tudo o
que precisa, envia para o Singularity e ele instalará tudo para você. Essas listas são chamadas de
singularity recipes.</p>
<section id="primeira-maneira-construir-e-usar-um-sandbox">
<h4>Primeira maneira: construir e usar um sandbox<a class="headerlink" href="#primeira-maneira-construir-e-usar-um-sandbox" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Você pode se perguntar: <em>Em qual máquina devo construir um container?</em></p>
<p>Antes de tudo, você precisa escolher onde construirá o seu container. Essa
operação requer muita <strong>memória e alto uso da CPU</strong>.</p>
<div class="admonition warning">
<p class="admonition-title">Aviso</p>
<p>NÃO construa containers em nenhum nó de login!</p>
</div>
<ul>
<li><dl>
<dt>(Recomendado para iniciantes) Se você precisar usar o apt-get, você deve construir</dt><dd><p>o container em seu laptop com privilégios de superusuário. Você só precisará
instalar o Singularity em seu laptop. Usuários de Windows/Mac podem ver <a class="reference external" href="https://www.sylabs.io/guides/3.0/user-guide/installation.html#install-on-windows-or-mac">there</a>
e usuários de Ubuntu/Debian podem usar diretamente:</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">sudo apt-get install singularity-container</span>
</pre></div>
</div>
</div></blockquote>
</dd>
</dl>
</li>
</ul>
<p>Nesse caso, para evitar muita entrada/saída (I/O) na rede, você deve definir o cache do
Singularity localmente:</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">export SINGULARITY_CACHEDIR=$SLURM_TMPDIR</span>
</pre></div>
</div>
</div></blockquote>
<ul class="simple">
<li><dl class="simple">
<dt>Se você <strong>não pode instalar o Singularity</strong> em seu laptop e <strong>deseja usar o apt-get</strong>,</dt><dd><p>você pode usar o <a class="reference external" href="https://www.singularity-hub.org/">singularity-hub</a> para construir seus containers e ler a seção
<a class="reference internal" href="#recipe-section">Recipe_section</a>.</p>
</dd>
</dl>
</li>
</ul>
<section id="baixando-containers-da-web">
<h5>Baixando containers da web.<a class="headerlink" href="#baixando-containers-da-web" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Felizmente, você pode não precisar criar containers do zero, pois muitos já foram
construídos para os softwares de deep learning mais comuns. Você pode encontrá-los
na maioria em <a class="reference external" href="https://hub.docker.com/">dockerhub</a>.</p>
<p>Acesse <a class="reference external" href="https://hub.docker.com/">dockerhub</a> e selecione o container que você deseja baixar</p>
<p>Por exemplo, se você deseja obter a última versão do PyTorch com suporte para GPU
(Substitua <em>runtime</em> por <em>devel</em> se precisar do conjunto completo de ferramentas do Cuda):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity pull docker://pytorch/pytorch:1.0.1-cuda10.0-cudnn7-runtime</span>
</pre></div>
</div>
<p>Ou a última versão do TensorFlow:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity pull docker://tensorflow/tensorflow:latest-gpu-py3</span>
</pre></div>
</div>
<p>Atualmente, a imagem baixada <code class="docutils literal notranslate"><span class="pre">pytorch.simg</span></code> ou <code class="docutils literal notranslate"><span class="pre">tensorflow.simg</span></code> é somente leitura,
o que significa que você não poderá instalar nada nela. A partir de agora, o PyTorch
será usado como exemplo. Se você estiver usando o TensorFlow, simplesmente substitua
todas as ocorrências de <strong>pytorch</strong> por <strong>tensorflow</strong>.</p>
</section>
<section id="como-adicionar-ou-instalar-coisas-em-um-container">
<h5>Como adicionar ou instalar coisas em um container<a class="headerlink" href="#como-adicionar-ou-instalar-coisas-em-um-container" title="Link permanente para este cabeçalho">¶</a></h5>
<p>O primeiro passo é transformar o seu container somente leitura
<code class="docutils literal notranslate"><span class="pre">pytorch-1.0.1-cuda10.0-cudnn7-runtime.simg</span></code> em uma versão gravável que
permitirá que você adicione pacotes.</p>
<div class="admonition warning">
<p class="admonition-title">Aviso</p>
<p>Dependendo da versão do singularity que você está usando, o singularity criará um container
com a extensão .simg ou .sif. Se você estiver usando arquivos .sif, substitua todas as ocorrências
de .simg por .sif.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Dica</p>
<p>Se você quiser usar o apt-get, deve colocar sudo antes dos comandos a seguir</p>
</div>
<p>Este comando criará uma imagem gravável na pasta <code class="docutils literal notranslate"><span class="pre">pytorch</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity build --sandbox pytorch pytorch-1.0.1-cuda10.0-cudnn7-runtime.simg</span>
</pre></div>
</div>
<p>Então você precisará do seguinte comando para fazer login dentro do container.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity shell --writable -H $HOME:/home pytorch</span>
</pre></div>
</div>
<p>Assim que você entrar no container, pode usar o pip e instalar tudo o que precisar
(ou usar <code class="docutils literal notranslate"><span class="pre">apt-get</span></code> se você construiu o container com sudo).</p>
<div class="admonition warning">
<p class="admonition-title">Aviso</p>
<p>O Singularity monta sua pasta pessoal, então se você instalar coisas no
diretório <code class="docutils literal notranslate"><span class="pre">$HOME</span></code> do seu container, elas serão instaladas no seu <code class="docutils literal notranslate"><span class="pre">$HOME</span></code> real!</p>
</div>
<p>Você deve instalar seus pacotes em /usr/local.</p>
</section>
<section id="criando-diretorios-uteis">
<h5>Criando diretórios úteis<a class="headerlink" href="#criando-diretorios-uteis" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Um dos benefícios dos containers é que você poderá usá-los em diferentes clusters.
No entanto, para cada cluster, a localização das pastas de datasets e experimentos
pode ser diferente. Para ser invariante em relação a essas localizações, criaremos
alguns pontos de montagem úteis dentro do container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">mkdir /dataset</span>
<span class="go">mkdir /tmp_log</span>
<span class="go">mkdir /final_log</span>
</pre></div>
</div>
<p>A partir de agora, você não precisará mais se preocupar em especificar onde buscar
seu conjunto de dados ao escrever seu código. Seu conjunto de dados estará sempre
em <code class="docutils literal notranslate"><span class="pre">/dataset</span></code>, independentemente do cluster que você estiver usando.</p>
</section>
<section id="testes">
<h5>Testes<a class="headerlink" href="#testes" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Se você tem algum código que deseja testar antes de finalizar o seu contêiner,
você tem duas opções. Você pode entrar no seu contêiner e executar o código
Python dentro dele com:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity shell --nv pytorch</span>
</pre></div>
</div>
<p>Ou você pode executar seu comando diretamente com:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity exec --nv pytorch Python YOUR_CODE.py</span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Dica</p>
<p>—nv permite que o container use GPUs. Você não precisa disso se não planeja usar uma GPU.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Aviso</p>
<p>Não se esqueça de limpar o cache dos pacotes que você instalou nos containers.</p>
</div>
</section>
<section id="criando-uma-nova-imagem-a-partir-do-sandbox">
<h5>Criando uma nova imagem a partir do sandbox<a class="headerlink" href="#criando-uma-nova-imagem-a-partir-do-sandbox" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Depois que tudo o que você precisa estiver instalado dentro do contêiner,
você precisa convertê-lo de volta em uma imagem singularity somente leitura com:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity build pytorch_final.simg pytorch</span>
</pre></div>
</div>
</section>
</section>
<section id="segunda-opcao-use-receitas">
<span id="recipe-section"></span><h4>Segunda opção: Use receitas<a class="headerlink" href="#segunda-opcao-use-receitas" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Uma receita do Singularity é um arquivo que inclui especificações sobre a instalação
de software, variáveis de ambiente, arquivos a serem adicionados e metadados do contêiner.
É um ponto de partida para projetar qualquer contêiner personalizado. Em vez de baixar um
contêiner e instalar seus pacotes manualmente, você pode especificar neste arquivo os pacotes
que deseja e, em seguida, construir seu contêiner a partir deste arquivo.</p>
<p>Aqui está um exemplo simples de uma receita do Singularity que instala alguns pacotes:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span><span class="c1">################ Header: Define the base system you want to use ################</span>
<span class="gp"># </span>Reference<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>kind<span class="w"> </span>of<span class="w"> </span>base<span class="w"> </span>you<span class="w"> </span>want<span class="w"> </span>to<span class="w"> </span>use<span class="w"> </span><span class="o">(</span>e.g.,<span class="w"> </span>docker,<span class="w"> </span>debootstrap,<span class="w"> </span>shub<span class="o">)</span>.
<span class="go">Bootstrap: docker</span>
<span class="gp"># </span>Select<span class="w"> </span>the<span class="w"> </span>docker<span class="w"> </span>image<span class="w"> </span>you<span class="w"> </span>want<span class="w"> </span>to<span class="w"> </span>use<span class="w"> </span><span class="o">(</span>Here<span class="w"> </span>we<span class="w"> </span>choose<span class="w"> </span>tensorflow<span class="o">)</span>
<span class="go">From: tensorflow/tensorflow:latest-gpu-py3</span>

<span class="gp">#</span><span class="c1">################ Section: Defining the system #################################</span>
<span class="gp"># </span>Commands<span class="w"> </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>%post<span class="w"> </span>section<span class="w"> </span>are<span class="w"> </span>executed<span class="w"> </span>within<span class="w"> </span>the<span class="w"> </span>container.
<span class="gp">%</span>post
<span class="go">        echo &quot;Installing Tools with apt-get&quot;</span>
<span class="go">        apt-get update</span>
<span class="go">        apt-get install -y cmake libcupti-dev libyaml-dev wget unzip</span>
<span class="go">        apt-get clean</span>
<span class="go">        echo &quot;Installing things with pip&quot;</span>
<span class="go">        pip install tqdm</span>
<span class="go">        echo &quot;Creating mount points&quot;</span>
<span class="go">        mkdir /dataset</span>
<span class="go">        mkdir /tmp_log</span>
<span class="go">        mkdir /final_log</span>


<span class="gp"># </span>Environment<span class="w"> </span>variables<span class="w"> </span>that<span class="w"> </span>should<span class="w"> </span>be<span class="w"> </span>sourced<span class="w"> </span>at<span class="w"> </span>runtime.
<span class="gp">%</span>environment
<span class="gp">        # </span>use<span class="w"> </span>bash<span class="w"> </span>as<span class="w"> </span>default<span class="w"> </span>shell
<span class="go">        SHELL=/bin/bash</span>
<span class="go">        export SHELL</span>
</pre></div>
</div>
<p>Um arquivo de receita contém duas partes: o “cabeçalho” (header) e “seções” (sections).
No “cabeçalho”, você especifica qual sistema base deseja usar, pode ser qualquer contêiner
do Docker ou do Singularity. Em “seções”, você pode listar as coisas que deseja instalar
na subseção “post” ou listar as variáveis de ambiente que precisa carregar em cada execução
na subseção “environment”. Para uma descrição mais detalhada, consulte <a class="reference external" href="https://www.sylabs.io/guides/2.6/user-guide/container_recipes.html#container-recipes">singularity documentation</a>.</p>
<p>Para construir um container singularity a partir de um arquivo de receita, você deve usar:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">sudo singularity build &lt;NAME_CONTAINER&gt; &lt;YOUR_RECIPE_FILES&gt;</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Aviso</p>
<p>Você sempre precisa usar o sudo ao construir um contêiner a partir de uma receita.
Como não há acesso ao sudo no cluster, é necessário um computador pessoal ou o uso do singularity
hub para construir um contêiner.</p>
</div>
<section id="construir-receita-no-singularity-hub">
<h5>Construir receita no Singularity Hub<a class="headerlink" href="#construir-receita-no-singularity-hub" title="Link permanente para este cabeçalho">¶</a></h5>
<p>O Singularity Hub permite que os usuários criem contêineres a partir de receitas
diretamente na nuvem do Singularity Hub, o que significa que você não precisa criar
contêineres sozinho. Você precisa se registrar no <a class="reference external" href="https://www.singularity-hub.org/">singularity-hub</a> e vincular sua conta
do Singularity Hub à sua conta do GitHub, e então:</p>
<blockquote>
<div><blockquote>
<div><ol class="arabic simple">
<li><p>Crie um novo repositório no Github.</p></li>
<li><p>Adicione uma coleção no <a class="reference external" href="https://www.singularity-hub.org/">singularity-hub</a> e selecione o repositório do Github que você criou.</p></li>
<li><p>Clone o repositório do Github em seu computador.</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ git clone &lt;url&gt;
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple">
<li><p>Write the singularity recipe and save it as a file named <strong>Singularity</strong>.</p></li>
<li><p>Git add <strong>Singularity</strong>, commit and push on the master branch</p></li>
</ol>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ git add Singularity
$ git commit
$ git push origin master
</pre></div>
</div>
</div></blockquote>
</div></blockquote>
<p>Neste ponto, os robôs do singularity-hub irão construir o contêiner para você,
e você poderá baixá-lo do site ou diretamente usando:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity pull shub://&lt;github_username&gt;/&lt;repository_name&gt;</span>
</pre></div>
</div>
</section>
<section id="exemplo-receita-com-openai-gym-mujoco-e-miniworld">
<h5>Exemplo: Receita com OpenAI gym, MuJoCo e Miniworld<a class="headerlink" href="#exemplo-receita-com-openai-gym-mujoco-e-miniworld" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Aqui está um exemplo de como você pode usar uma receita do Singularity
para instalar um ambiente complexo como o OpenAI gym, MuJoCo e Miniworld
em um contêiner baseado em PyTorch.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span>This<span class="w"> </span>is<span class="w"> </span>a<span class="w"> </span>dockerfile<span class="w"> </span>that<span class="w"> </span>sets<span class="w"> </span>up<span class="w"> </span>a<span class="w"> </span>full<span class="w"> </span>Gym<span class="w"> </span>install<span class="w"> </span>with<span class="w"> </span><span class="nb">test</span><span class="w"> </span>dependencies
<span class="go">Bootstrap: docker</span>

<span class="gp"># </span>Here<span class="w"> </span>we<span class="w"> </span>ll<span class="w"> </span>build<span class="w"> </span>our<span class="w"> </span>container<span class="w"> </span>upon<span class="w"> </span>the<span class="w"> </span>pytorch<span class="w"> </span>container
<span class="go">From: pytorch/pytorch:1.0-cuda10.0-cudnn7-runtime</span>

<span class="gp"># </span>Now<span class="w"> </span>we<span class="s1">&#39;ll copy the mjkey file located in the current directory inside the container&#39;</span>s<span class="w"> </span>root
<span class="gp"># </span>directory
<span class="gp">%</span>files
<span class="go">        mjkey.txt</span>

<span class="gp"># </span>Then<span class="w"> </span>we<span class="w"> </span>put<span class="w"> </span>everything<span class="w"> </span>we<span class="w"> </span>need<span class="w"> </span>to<span class="w"> </span>install
<span class="gp">%</span>post
<span class="go">        export PATH=$PATH:/opt/conda/bin</span>
<span class="go">        apt -y update &amp;&amp; \</span>
<span class="go">        apt install -y keyboard-configuration &amp;&amp; \</span>
<span class="go">        apt install -y \</span>
<span class="go">        python3-dev \</span>
<span class="go">        python-pyglet \</span>
<span class="go">        python3-opengl \</span>
<span class="go">        libhdf5-dev \</span>
<span class="go">        libjpeg-dev \</span>
<span class="go">        libboost-all-dev \</span>
<span class="go">        libsdl2-dev \</span>
<span class="go">        libosmesa6-dev \</span>
<span class="go">        patchelf \</span>
<span class="go">        ffmpeg \</span>
<span class="go">        xvfb \</span>
<span class="go">        libhdf5-dev \</span>
<span class="go">        openjdk-8-jdk \</span>
<span class="go">        wget \</span>
<span class="go">        git \</span>
<span class="go">        unzip &amp;&amp; \</span>
<span class="go">        apt clean &amp;&amp; \</span>
<span class="go">        rm -rf /var/lib/apt/lists/*</span>
<span class="go">        pip install h5py</span>

<span class="gp">        # </span>Download<span class="w"> </span>Gym<span class="w"> </span>and<span class="w"> </span>MuJoCo
<span class="go">        mkdir /Gym &amp;&amp; cd /Gym</span>
<span class="go">        git clone https://github.com/openai/gym.git || true &amp;&amp; \</span>
<span class="go">        mkdir /Gym/.mujoco &amp;&amp; cd /Gym/.mujoco</span>
<span class="go">        wget https://www.roboti.us/download/mjpro150_linux.zip  &amp;&amp; \</span>
<span class="go">        unzip mjpro150_linux.zip &amp;&amp; \</span>
<span class="go">        wget https://www.roboti.us/download/mujoco200_linux.zip &amp;&amp; \</span>
<span class="go">        unzip mujoco200_linux.zip &amp;&amp; \</span>
<span class="go">        mv mujoco200_linux mujoco200</span>

<span class="gp">        # </span>Export<span class="w"> </span>global<span class="w"> </span>environment<span class="w"> </span>variables
<span class="go">        export MUJOCO_PY_MJKEY_PATH=/Gym/.mujoco/mjkey.txt</span>
<span class="go">        export MUJOCO_PY_MUJOCO_PATH=/Gym/.mujoco/mujoco150/</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/Gym/.mujoco/mjpro150/bin</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/Gym/.mujoco/mujoco200/bin</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/bin</span>
<span class="go">        cp /mjkey.txt /Gym/.mujoco/mjkey.txt</span>
<span class="gp">        # </span>Install<span class="w"> </span>Python<span class="w"> </span>dependencies
<span class="go">        wget https://raw.githubusercontent.com/openai/mujoco-py/master/requirements.txt</span>
<span class="go">        pip install -r requirements.txt</span>
<span class="gp">        # </span>Install<span class="w"> </span>Gym<span class="w"> </span>and<span class="w"> </span>MuJoCo
<span class="go">        cd /Gym/gym</span>
<span class="go">        pip install -e &#39;.[all]&#39;</span>
<span class="gp">        # </span>Change<span class="w"> </span>permission<span class="w"> </span>to<span class="w"> </span>use<span class="w"> </span>mujoco_py<span class="w"> </span>as<span class="w"> </span>non<span class="w"> </span>sudoer<span class="w"> </span>user
<span class="go">        chmod -R 777 /opt/conda/lib/python3.6/site-packages/mujoco_py/</span>
<span class="go">        pip install --upgrade minerl</span>

<span class="gp"># </span>Export<span class="w"> </span>global<span class="w"> </span>environment<span class="w"> </span>variables
<span class="gp">%</span>environment
<span class="go">        export SHELL=/bin/sh</span>
<span class="go">        export MUJOCO_PY_MJKEY_PATH=/Gym/.mujoco/mjkey.txt</span>
<span class="go">        export MUJOCO_PY_MUJOCO_PATH=/Gym/.mujoco/mujoco150/</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/Gym/.mujoco/mjpro150/bin</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/Gym/.mujoco/mujoco200/bin</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/bin</span>
<span class="go">        export PATH=/Gym/gym/.tox/py3/bin:$PATH</span>

<span class="gp">%</span>runscript
<span class="go">        exec /bin/sh &quot;$@&quot;</span>
</pre></div>
</div>
<p>Here is the same recipe but written for TensorFlow:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span>This<span class="w"> </span>is<span class="w"> </span>a<span class="w"> </span>dockerfile<span class="w"> </span>that<span class="w"> </span>sets<span class="w"> </span>up<span class="w"> </span>a<span class="w"> </span>full<span class="w"> </span>Gym<span class="w"> </span>install<span class="w"> </span>with<span class="w"> </span><span class="nb">test</span><span class="w"> </span>dependencies
<span class="go">Bootstrap: docker</span>

<span class="gp"># </span>Here<span class="w"> </span>we<span class="w"> </span>ll<span class="w"> </span>build<span class="w"> </span>our<span class="w"> </span>container<span class="w"> </span>upon<span class="w"> </span>the<span class="w"> </span>tensorflow<span class="w"> </span>container
<span class="go">From: tensorflow/tensorflow:latest-gpu-py3</span>

<span class="gp"># </span>Now<span class="w"> </span>we<span class="s1">&#39;ll copy the mjkey file located in the current directory inside the container&#39;</span>s<span class="w"> </span>root
<span class="gp"># </span>directory
<span class="gp">%</span>files
<span class="go">        mjkey.txt</span>

<span class="gp"># </span>Then<span class="w"> </span>we<span class="w"> </span>put<span class="w"> </span>everything<span class="w"> </span>we<span class="w"> </span>need<span class="w"> </span>to<span class="w"> </span>install
<span class="gp">%</span>post
<span class="go">        apt -y update &amp;&amp; \</span>
<span class="go">        apt install -y keyboard-configuration &amp;&amp; \</span>
<span class="go">        apt install -y \</span>
<span class="go">        python3-setuptools \</span>
<span class="go">        python3-dev \</span>
<span class="go">        python-pyglet \</span>
<span class="go">        python3-opengl \</span>
<span class="go">        libjpeg-dev \</span>
<span class="go">        libboost-all-dev \</span>
<span class="go">        libsdl2-dev \</span>
<span class="go">        libosmesa6-dev \</span>
<span class="go">        patchelf \</span>
<span class="go">        ffmpeg \</span>
<span class="go">        xvfb \</span>
<span class="go">        wget \</span>
<span class="go">        git \</span>
<span class="go">        unzip &amp;&amp; \</span>
<span class="go">        apt clean &amp;&amp; \</span>
<span class="go">        rm -rf /var/lib/apt/lists/*</span>

<span class="gp">        # </span>Download<span class="w"> </span>Gym<span class="w"> </span>and<span class="w"> </span>MuJoCo
<span class="go">        mkdir /Gym &amp;&amp; cd /Gym</span>
<span class="go">        git clone https://github.com/openai/gym.git || true &amp;&amp; \</span>
<span class="go">        mkdir /Gym/.mujoco &amp;&amp; cd /Gym/.mujoco</span>
<span class="go">        wget https://www.roboti.us/download/mjpro150_linux.zip  &amp;&amp; \</span>
<span class="go">        unzip mjpro150_linux.zip &amp;&amp; \</span>
<span class="go">        wget https://www.roboti.us/download/mujoco200_linux.zip &amp;&amp; \</span>
<span class="go">        unzip mujoco200_linux.zip &amp;&amp; \</span>
<span class="go">        mv mujoco200_linux mujoco200</span>

<span class="gp">        # </span>Export<span class="w"> </span>global<span class="w"> </span>environment<span class="w"> </span>variables
<span class="go">        export MUJOCO_PY_MJKEY_PATH=/Gym/.mujoco/mjkey.txt</span>
<span class="go">        export MUJOCO_PY_MUJOCO_PATH=/Gym/.mujoco/mujoco150/</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/Gym/.mujoco/mjpro150/bin</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/Gym/.mujoco/mujoco200/bin</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/bin</span>
<span class="go">        cp /mjkey.txt /Gym/.mujoco/mjkey.txt</span>

<span class="gp">        # </span>Install<span class="w"> </span>Python<span class="w"> </span>dependencies
<span class="go">        wget https://raw.githubusercontent.com/openai/mujoco-py/master/requirements.txt</span>
<span class="go">        pip install -r requirements.txt</span>
<span class="gp">        # </span>Install<span class="w"> </span>Gym<span class="w"> </span>and<span class="w"> </span>MuJoCo
<span class="go">        cd /Gym/gym</span>
<span class="go">        pip install -e &#39;.[all]&#39;</span>
<span class="gp">        # </span>Change<span class="w"> </span>permission<span class="w"> </span>to<span class="w"> </span>use<span class="w"> </span>mujoco_py<span class="w"> </span>as<span class="w"> </span>non<span class="w"> </span>sudoer<span class="w"> </span>user
<span class="go">        chmod -R 777 /usr/local/lib/python3.5/dist-packages/mujoco_py/</span>

<span class="gp">        # </span>Then<span class="w"> </span>install<span class="w"> </span>miniworld
<span class="go">        cd /usr/local/</span>
<span class="go">        git clone https://github.com/maximecb/gym-miniworld.git</span>
<span class="go">        cd gym-miniworld</span>
<span class="go">        pip install -e .</span>

<span class="gp"># </span>Export<span class="w"> </span>global<span class="w"> </span>environment<span class="w"> </span>variables
<span class="gp">%</span>environment
<span class="go">        export SHELL=/bin/bash</span>
<span class="go">        export MUJOCO_PY_MJKEY_PATH=/Gym/.mujoco/mjkey.txt</span>
<span class="go">        export MUJOCO_PY_MUJOCO_PATH=/Gym/.mujoco/mujoco150/</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/Gym/.mujoco/mjpro150/bin</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/Gym/.mujoco/mujoco200/bin</span>
<span class="go">        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/bin</span>
<span class="go">        export PATH=/Gym/gym/.tox/py3/bin:$PATH</span>

<span class="gp">%</span>runscript
<span class="go">        exec /bin/bash &quot;$@&quot;</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="usando-conteiners-no-cluster">
<span id="using-containers"></span><h3>Usando Conteiners no cluster<a class="headerlink" href="#usando-conteiners-no-cluster" title="Link permanente para este cabeçalho">¶</a></h3>
<section id="como-usar-conteiners-no-cluster">
<h4>Como usar conteiners no cluster<a class="headerlink" href="#como-usar-conteiners-no-cluster" title="Link permanente para este cabeçalho">¶</a></h4>
<p>Em todo cluster com Slurm, os conjuntos de dados e resultados intermediários
devem ser armazenados em <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code>, enquanto os resultados finais do
experimento devem ser salvos em <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code>. Para usar o contêiner que você criou,
é necessário copiá-lo para o cluster que deseja usar.</p>
<div class="admonition warning">
<p class="admonition-title">Aviso</p>
<p>Você sempre deve armazenar o seu contêiner em $SCRATCH!</p>
</div>
<p>Em seguida, reserve um nó com srun/sbatch, copie o contêiner e o seu conjunto de
dados para o nó fornecido pelo SLURM (ou seja, em <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code>) e execute o
código <code class="docutils literal notranslate"><span class="pre">&lt;YOUR_CODE&gt;</span></code> dentro do contêiner <code class="docutils literal notranslate"><span class="pre">&lt;YOUR_CONTAINER&gt;</span></code> com:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity exec --nv -H $HOME:/home -B $SLURM_TMPDIR:/dataset/ -B $SLURM_TMPDIR:/tmp_log/ -B $SCRATCH:/final_log/ $SLURM_TMPDIR/&lt;YOUR_CONTAINER&gt; python &lt;YOUR_CODE&gt;</span>
</pre></div>
</div>
<p>Remember that <code class="docutils literal notranslate"><span class="pre">/dataset</span></code>, <code class="docutils literal notranslate"><span class="pre">/tmp_log</span></code> and <code class="docutils literal notranslate"><span class="pre">/final_log</span></code> were created in the
previous section. Now each time, we’ll use singularity, we are explicitly
telling it to mount <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code> on the cluster’s node in the folder
<code class="docutils literal notranslate"><span class="pre">/dataset</span></code> inside the container with the option <code class="docutils literal notranslate"><span class="pre">-B</span></code> such that each dataset
downloaded by PyTorch in <code class="docutils literal notranslate"><span class="pre">/dataset</span></code> will be available in <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code>.</p>
<p>This will allow us to have code and scripts that are invariant to the cluster
environment. The option <code class="docutils literal notranslate"><span class="pre">-H</span></code> specify what will be the container’s home. For
example, if you have your code in <code class="docutils literal notranslate"><span class="pre">$HOME/Project12345/Version35/</span></code> you can
specify <code class="docutils literal notranslate"><span class="pre">-H</span> <span class="pre">$HOME/Project12345/Version35:/home</span></code>, thus the container will only
have access to the code inside <code class="docutils literal notranslate"><span class="pre">Version35</span></code>.</p>
<p>If you want to run multiple commands inside the container you can use:</p>
<p>Lembre-se de que <code class="docutils literal notranslate"><span class="pre">/dataset</span></code>, <code class="docutils literal notranslate"><span class="pre">/tmp_log</span></code> e <code class="docutils literal notranslate"><span class="pre">/final_log</span></code> foram criados na seção anterior.
Agora, cada vez que usarmos o singularity, estamos explicitamente dizendo a ele
para montar <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code> no nó do cluster na pasta <code class="docutils literal notranslate"><span class="pre">/dataset</span></code> dentro do container
com a opção <code class="docutils literal notranslate"><span class="pre">-B</span></code>, de modo que cada conjunto de dados baixado pelo PyTorch em <code class="docutils literal notranslate"><span class="pre">/dataset</span></code>
estará disponível em <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code>.</p>
<p>Isso nos permitirá ter código e scripts que são invariantes ao ambiente do cluster.
A opção <code class="docutils literal notranslate"><span class="pre">-H</span></code> especifica qual será o diretório raiz do container. Por exemplo, se você
tem seu código em <code class="docutils literal notranslate"><span class="pre">$HOME/Projeto12345/Versao35/</span></code>, você pode especificar
<code class="docutils literal notranslate"><span class="pre">-H</span> <span class="pre">$HOME/Projeto12345/Versao35:/home</span></code>, assim o container terá acesso apenas ao código dentro de <code class="docutils literal notranslate"><span class="pre">Versao35</span></code>.</p>
<p>Se você quiser executar vários comandos dentro do container, pode usar:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity exec --nv -H $HOME:/home -B $SLURM_TMPDIR:/dataset/ \</span>
<span class="go">    -B $SLURM_TMPDIR:/tmp_log/ -B $SCRATCH:/final_log/ \</span>
<span class="gp">    $</span>SLURM_TMPDIR/&lt;YOUR_CONTAINER&gt;<span class="w"> </span>bash<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;pwd &amp;&amp; ls &amp;&amp; python &lt;YOUR_CODE&gt;&#39;</span>
</pre></div>
</div>
<section id="exemplo-caso-interativo-srun-salloc">
<h5>Exemplo: Caso interativo (srun/salloc)<a class="headerlink" href="#exemplo-caso-interativo-srun-salloc" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Depois de obter uma sessão interativa com o SLURM, copie <code class="docutils literal notranslate"><span class="pre">&lt;YOUR_CONTAINER&gt;</span></code> e
<code class="docutils literal notranslate"><span class="pre">&lt;YOUR_DATASET&gt;</span></code> para <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span><span class="m">0</span>.<span class="w"> </span>Get<span class="w"> </span>an<span class="w"> </span>interactive<span class="w"> </span>session
<span class="gp">$ </span>srun<span class="w"> </span>--gres<span class="o">=</span>gpu:1
<span class="gp"># </span><span class="m">1</span>.<span class="w"> </span>Copy<span class="w"> </span>your<span class="w"> </span>container<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span>compute<span class="w"> </span>node
<span class="gp">$ </span>rsync<span class="w"> </span>-avz<span class="w"> </span><span class="nv">$SCRATCH</span>/&lt;YOUR_CONTAINER&gt;<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>
<span class="gp"># </span><span class="m">2</span>.<span class="w"> </span>Copy<span class="w"> </span>your<span class="w"> </span>dataset<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span>compute<span class="w"> </span>node
<span class="gp">$ </span>rsync<span class="w"> </span>-avz<span class="w"> </span><span class="nv">$SCRATCH</span>/&lt;YOUR_DATASET&gt;<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>
</pre></div>
</div>
<p>Então, use o comando <code class="docutils literal notranslate"><span class="pre">singularity</span> <span class="pre">shell</span></code> para obter um shell dentro do contêiner.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span><span class="m">3</span>.<span class="w"> </span>Get<span class="w"> </span>a<span class="w"> </span>shell<span class="w"> </span><span class="k">in</span><span class="w"> </span>your<span class="w"> </span>environment
<span class="gp">$ </span>singularity<span class="w"> </span>shell<span class="w"> </span>--nv<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>-H<span class="w"> </span><span class="nv">$HOME</span>:/home<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>-B<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>:/dataset/<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>-B<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>:/tmp_log/<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>-B<span class="w"> </span><span class="nv">$SCRATCH</span>:/final_log/<span class="w"> </span><span class="se">\</span>
<span class="gp">        $</span>SLURM_TMPDIR/&lt;YOUR_CONTAINER&gt;
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span><span class="m">4</span>.<span class="w"> </span>Execute<span class="w"> </span>your<span class="w"> </span>code
<span class="go">&lt;Singularity_container&gt;$ python &lt;YOUR_CODE&gt;</span>
</pre></div>
</div>
<p><strong>or</strong> use <code class="docutils literal notranslate"><span class="pre">singularity</span> <span class="pre">exec</span></code> to execute <code class="docutils literal notranslate"><span class="pre">&lt;YOUR_CODE&gt;</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span><span class="m">3</span>.<span class="w"> </span>Execute<span class="w"> </span>your<span class="w"> </span>code
<span class="gp">$ </span>singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>-H<span class="w"> </span><span class="nv">$HOME</span>:/home<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>-B<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>:/dataset/<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>-B<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>:/tmp_log/<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>-B<span class="w"> </span><span class="nv">$SCRATCH</span>:/final_log/<span class="w"> </span><span class="se">\</span>
<span class="gp">        $</span>SLURM_TMPDIR/&lt;YOUR_CONTAINER&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>python<span class="w"> </span>&lt;YOUR_CODE&gt;
</pre></div>
</div>
<p>Você também pode criar o seguinte alias para facilitar sua vida:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span>alias my_env=&#39;singularity exec --nv \
        -H $HOME:/home \
        -B $SLURM_TMPDIR:/dataset/ \
        -B $SLURM_TMPDIR:/tmp_log/ \
        -B $SCRATCH:/final_log/ \
        $SLURM_TMPDIR/&lt;YOUR_CONTAINER&gt;&#39;
</pre></div>
</div>
<p>Isso permitirá que você execute qualquer código com:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">my_env python &lt;YOUR_CODE&gt;</span>
</pre></div>
</div>
</section>
<section id="exemplo-caso-sbatch">
<h5>Exemplo: caso sbatch<a class="headerlink" href="#exemplo-caso-sbatch" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Você também pode criar um script <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span>!/bin/bash
<span class="gp">#</span>SBATCH<span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">6</span><span class="w">         </span><span class="c1"># Ask for 6 CPUs</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w">              </span><span class="c1"># Ask for 1 GPU</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--mem<span class="o">=</span>10G<span class="w">                 </span><span class="c1"># Ask for 10 GB of RAM</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--time<span class="o">=</span><span class="m">0</span>:10:00<span class="w">            </span><span class="c1"># The job will run for 10 minutes</span>

<span class="gp"># </span><span class="m">1</span>.<span class="w"> </span>Copy<span class="w"> </span>your<span class="w"> </span>container<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span>compute<span class="w"> </span>node
<span class="go">rsync -avz $SCRATCH/&lt;YOUR_CONTAINER&gt; $SLURM_TMPDIR</span>
<span class="gp"># </span><span class="m">2</span>.<span class="w"> </span>Copy<span class="w"> </span>your<span class="w"> </span>dataset<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span>compute<span class="w"> </span>node
<span class="go">rsync -avz $SCRATCH/&lt;YOUR_DATASET&gt; $SLURM_TMPDIR</span>
<span class="gp"># </span><span class="m">3</span>.<span class="w"> </span>Executing<span class="w"> </span>your<span class="w"> </span>code<span class="w"> </span>with<span class="w"> </span>singularity
<span class="go">singularity exec --nv \</span>
<span class="go">        -H $HOME:/home \</span>
<span class="go">        -B $SLURM_TMPDIR:/dataset/ \</span>
<span class="go">        -B $SLURM_TMPDIR:/tmp_log/ \</span>
<span class="go">        -B $SCRATCH:/final_log/ \</span>
<span class="gp">        $</span>SLURM_TMPDIR/&lt;YOUR_CONTAINER&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>python<span class="w"> </span><span class="s2">&quot;&lt;YOUR_CODE&gt;&quot;</span>
<span class="gp"># </span><span class="m">4</span>.<span class="w"> </span>Copy<span class="w"> </span>whatever<span class="w"> </span>you<span class="w"> </span>want<span class="w"> </span>to<span class="w"> </span>save<span class="w"> </span>on<span class="w"> </span><span class="nv">$SCRATCH</span>
<span class="go">rsync -avz $SLURM_TMPDIR/&lt;to_save&gt; $SCRATCH</span>
</pre></div>
</div>
</section>
<section id="problema-com-as-bibliotecas-pybullet-e-opengl">
<h5>Problema com as bibliotecas PyBullet e OpenGL<a class="headerlink" href="#problema-com-as-bibliotecas-pybullet-e-opengl" title="Link permanente para este cabeçalho">¶</a></h5>
<p>Se você estiver executando certos ambientes do gym que requerem o <code class="docutils literal notranslate"><span class="pre">pyglet</span></code>,
você pode encontrar um problema ao executar sua instância do singularity
com os drivers Nvidia usando a flag <code class="docutils literal notranslate"><span class="pre">--nv</span></code>. Isso acontece porque a flag <code class="docutils literal notranslate"><span class="pre">--nv</span></code>
também fornece as bibliotecas do OpenGL:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">libGL.so.1 =&gt; /.singularity.d/libs/libGL.so.1</span>
<span class="go">libGLX.so.0 =&gt; /.singularity.d/libs/libGLX.so.0</span>
</pre></div>
</div>
<p>Se você não está tendo esses problemas com <code class="docutils literal notranslate"><span class="pre">pyglet</span></code>, provavelmente não precisa se
preocupar com isso. Caso contrário, você pode resolver esses problemas com <code class="docutils literal notranslate"><span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">-y</span>
<span class="pre">libosmesa6-dev</span> <span class="pre">mesa-utils</span> <span class="pre">mesa-utils-extra</span> <span class="pre">libgl1-mesa-glx</span></code> e, em seguida, certificar-se de que
seu <code class="docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code> aponte para essas bibliotecas antes das que estão em <code class="docutils literal notranslate"><span class="pre">/</span> <span class="pre">.singularity.d</span> <span class="pre">/</span> <span class="pre">libs</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">%</span>environment
<span class="gp">        # </span>...
<span class="go">        export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/mesa:$LD_LIBRARY_PATH</span>
</pre></div>
</div>
</section>
<section id="apuana-cluster">
<h5>Apuana cluster<a class="headerlink" href="#apuana-cluster" title="Link permanente para este cabeçalho">¶</a></h5>
<p>No cluster Apuana, <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code> ainda não está definido, você deve adicionar os
resultados do experimento que deseja manter em <code class="docutils literal notranslate"><span class="pre">/network/scratch/&lt;u&gt;/&lt;username&gt;/</span></code>.
Para usar o script sbatch acima e para corresponder a outros nomes de ambiente de
cluster, você pode definir <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code> como um alias para <code class="docutils literal notranslate"><span class="pre">/network/scratch/&lt;u&gt;/&lt;username&gt;</span></code> com:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">echo &quot;export SCRATCH=/network/scratch/${USER:0:1}/$USER&quot; &gt;&gt; ~/.bashrc</span>
</pre></div>
</div>
<p>Então, você pode seguir o procedimento geral explicado acima.</p>
</section>
</section>
</section>
</section>
<section id="compartilhando-dados-com-acls">
<h2>Compartilhando dados com ACLs<a class="headerlink" href="#compartilhando-dados-com-acls" title="Link permanente para este cabeçalho">¶</a></h2>
<p>Os bits de permissão regulares são ferramentas extremamente limitadas: eles controlam
o acesso por meio de apenas três conjuntos de bits - usuário proprietário, grupo
proprietário e todos os outros. Portanto, o acesso é ou muito restrito
(0700 permite acesso apenas ao usuário proprietário) ou muito amplo
(770 dá todas as permissões para todos no mesmo grupo, e 777 para literalmente todos).</p>
<p>As ACLs (Listas de Controle de Acesso) são uma expansão dos bits de permissão que permitem
um controle mais granular de acessos a um arquivo. Elas podem ser usadas para permitir
que usuários específicos acessem arquivos e pastas, mesmo que as permissões padrão
conservadoras os tenham negado esse acesso.</p>
<p>Como exemplo ilustrativo, para usar as ACLs para permitir que $USER (a si mesmo) compartilhe
com $USER2 (outra pessoa) uma hierarquia de pastas “playground” no sistema de arquivos de
rascunho do Apuana em um local</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">/network/scratch/${USER:0:1}/$USER/X/Y/Z/...</span></code></p>
</div></blockquote>
<p>de maneira segura e que permita que ambos os usuários leiam, escrevam, executem, pesquisem e excluam
os arquivos um do outro:</p>
<hr class="docutils" />
<div class="line-block">
<div class="line"><strong>1.</strong> Grant <strong>oneself</strong> permissions to access any <strong>future</strong> files/folders created
by the other <em>(or oneself)</em></div>
<div class="line">(<code class="docutils literal notranslate"><span class="pre">-d</span></code> renders this permission a “default” / inheritable one)</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">setfacl -Rdm user:${USER}:rwx  /network/scratch/${USER:0:1}/$USER/X/Y/Z/</span>
</pre></div>
</div>
<hr class="docutils" />
<div class="admonition note">
<p class="admonition-title">Nota</p>
<blockquote>
<div><p>A importância de fazer este passo aparentemente redundante primeiro é que arquivos e
pastas são sempre de propriedade de apenas uma pessoa, quase sempre o seu criador
(o UID será do criador, o GID geralmente também). Se esse usuário não for você,
você não terá acesso a esses arquivos a menos que a outra pessoa especificamente os dê
a você - ou esses arquivos herdem uma ACL padrão que permita acesso total.</p>
</div></blockquote>
<p><strong>This</strong> Esta é a ACL padrão herdada que serve esse propósito.</p>
</div>
<div class="line-block">
<div class="line"><strong>2.</strong> Grant <strong>the other</strong> permission to access any <strong>future</strong> files/folders created
by the other <em>(or oneself)</em></div>
<div class="line">(<code class="docutils literal notranslate"><span class="pre">-d</span></code> renders this permission a “default” / inheritable one)</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">setfacl -Rdm user:${USER2}:rwx /network/scratch/${USER:0:1}/$USER/X/Y/Z/</span>
</pre></div>
</div>
<hr class="docutils" />
<div class="line-block">
<div class="line"><strong>3.</strong> Grant <strong>the other</strong> permission to access any <strong>existing</strong> files/folders created
by <em>oneself</em>.</div>
<div class="line">Esses arquivos e pastas foram criados antes das novas ACLs padrão serem adicionadas acima e,
portanto, não as herdaram de sua pasta pai no momento de sua criação.</div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">setfacl -Rm  user:${USER2}:rwx /network/scratch/${USER:0:1}/$USER/X/Y/Z/</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<dl class="simple">
<dt>O objetivo de conceder permissões primeiro para arquivos <em>futuros</em> e depois para arquivos</dt><dd><p>existentes é evitar uma condição de corrida em que, após o primeiro comando <code class="docutils literal notranslate"><span class="pre">setfacl</span></code>, a
outra pessoa possa criar arquivos aos quais o segundo comando <code class="docutils literal notranslate"><span class="pre">setfacl</span></code> não se aplica.</p>
</dd>
</dl>
</div>
<hr class="docutils" />
<div class="line-block">
<div class="line"><strong>4.</strong> Grant <strong>another</strong> permission to search through one’s hierarchy down to the
shared location in question.</div>
</div>
<ul class="simple">
<li><p><strong>Non</strong>-recursive (!!!!)</p></li>
<li><dl class="simple">
<dt>May also grant <code class="docutils literal notranslate"><span class="pre">:rx</span></code> in unlikely event others listing your folders on the</dt><dd><p>path is not troublesome or desirable.</p>
</dd>
</dl>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">setfacl -m   user:${USER2}:x   /network/scratch/${USER:0:1}/$USER/X/Y/</span>
<span class="go">setfacl -m   user:${USER2}:x   /network/scratch/${USER:0:1}/$USER/X/</span>
<span class="go">setfacl -m   user:${USER2}:x   /network/scratch/${USER:0:1}/$USER/</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Para acessar um arquivo, todas as pastas desde o diretório raiz (<code class="docutils literal notranslate"><span class="pre">/</span></code>) até a pasta pai
em questão devem ser pesquisáveis (+x) pelo usuário em questão. Isso já é o caso
para todos os usuários em pastas como <code class="docutils literal notranslate"><span class="pre">/</span></code>, <code class="docutils literal notranslate"><span class="pre">/network</span></code> e <code class="docutils literal notranslate"><span class="pre">/network/scratch</span></code>, mas os usuários
devem conceder acesso explicitamente a alguns ou a todos os usuários, seja por meio de
permissões básicas ou adicionando ACLs, para pelo menos <code class="docutils literal notranslate"><span class="pre">/network/scratch/${USER:0:1}/$USER</span></code>, <code class="docutils literal notranslate"><span class="pre">$HOME</span></code> e subpastas.</p>
<p>Para permitir bruscamente que todos os usuários pesquisem uma pasta (<strong>pense duas vezes!</strong>), o seguinte comando pode ser usado:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">chmod a+x /network/scratch/${USER:0:1}/$USER/</span>
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<blockquote>
<div><p>Para obter mais informações sobre <code class="docutils literal notranslate"><span class="pre">setfacl</span></code> e resolução de caminho/verificação
de acesso, considere os seguintes comandos de visualização de documentação:</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">man</span> <span class="pre">setfacl</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">man</span> <span class="pre">path_resolution</span></code></p></li>
</ul>
</div>
<section id="visualizando-e-verificando-acls">
<h3>Visualizando e Verificando ACLs<a class="headerlink" href="#visualizando-e-verificando-acls" title="Link permanente para este cabeçalho">¶</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">getfacl /path/to/folder/or/file</span>
<span class="go">            1:  # file: somedir/</span>
<span class="go">            2:  # owner: lisa</span>
<span class="go">            3:  # group: staff</span>
<span class="go">            4:  # flags: -s-</span>
<span class="go">            5:  user::rwx</span>
<span class="go">            6:  user:joe:rwx               #effective:r-x</span>
<span class="go">            7:  group::rwx                 #effective:r-x</span>
<span class="go">            8:  group:cool:r-x</span>
<span class="go">            9:  mask::r-x</span>
<span class="go">            10:  other::r-x</span>
<span class="go">            11:  default:user::rwx</span>
<span class="go">            12:  default:user:joe:rwx       #effective:r-x</span>
<span class="go">            13:  default:group::r-x</span>
<span class="go">            14:  default:mask::r-x</span>
<span class="go">            15:  default:other::---</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">man</span> <span class="pre">getfacl</span></code></p></li>
</ul>
</div>
</section>
</section>
<section id="nos-multiplos">
<h2>Nós Múltiplos<a class="headerlink" href="#nos-multiplos" title="Link permanente para este cabeçalho">¶</a></h2>
<section id="paralelismo-de-dados">
<h3>Paralelismo de Dados<a class="headerlink" href="#paralelismo-de-dados" title="Link permanente para este cabeçalho">¶</a></h3>
<img alt="../_images/dataparallel.png" src="../_images/dataparallel.png" />
<p>Solicite 3 nós com pelo menos 4 GPUs cada um.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span>!/bin/bash

<span class="gp"># </span>Number<span class="w"> </span>of<span class="w"> </span>Nodes
<span class="gp">#</span>SBATCH<span class="w"> </span>--nodes<span class="o">=</span><span class="m">3</span>

<span class="gp"># </span>Number<span class="w"> </span>of<span class="w"> </span>tasks.<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="o">(</span><span class="m">1</span><span class="w"> </span>per<span class="w"> </span>node<span class="o">)</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">3</span>

<span class="gp"># </span>Number<span class="w"> </span>of<span class="w"> </span>GPU<span class="w"> </span>per<span class="w"> </span>node
<span class="gp">#</span>SBATCH<span class="w"> </span>--gres<span class="o">=</span>gpu:4
<span class="gp">#</span>SBATCH<span class="w"> </span>--gpus-per-node<span class="o">=</span><span class="m">4</span>

<span class="gp"># </span><span class="m">16</span><span class="w"> </span>CPUs<span class="w"> </span>per<span class="w"> </span>node
<span class="gp">#</span>SBATCH<span class="w"> </span>--cpus-per-gpu<span class="o">=</span><span class="m">4</span>

<span class="gp"># </span>16Go<span class="w"> </span>per<span class="w"> </span>nodes<span class="w"> </span><span class="o">(</span>4Go<span class="w"> </span>per<span class="w"> </span>GPU<span class="o">)</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--mem<span class="o">=</span>16G

<span class="gp"># </span>we<span class="w"> </span>need<span class="w"> </span>all<span class="w"> </span>nodes<span class="w"> </span>to<span class="w"> </span>be<span class="w"> </span>ready<span class="w"> </span>at<span class="w"> </span>the<span class="w"> </span>same<span class="w"> </span><span class="nb">time</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--wait-all-nodes<span class="o">=</span><span class="m">1</span>

<span class="gp"># </span>Total<span class="w"> </span>resources:
<span class="gp">#   </span>CPU:<span class="w"> </span><span class="m">16</span><span class="w"> </span>*<span class="w"> </span><span class="nv">3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">48</span>
<span class="gp">#   </span>RAM:<span class="w"> </span><span class="m">16</span><span class="w"> </span>*<span class="w"> </span><span class="nv">3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">48</span><span class="w"> </span>Go
<span class="gp">#   </span>GPU:<span class="w">  </span><span class="m">4</span><span class="w"> </span>*<span class="w"> </span><span class="nv">3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">12</span>

<span class="gp"># </span>Setup<span class="w"> </span>our<span class="w"> </span>rendez-vous<span class="w"> </span>point
<span class="go">RDV_ADDR=$(hostname)</span>
<span class="go">WORLD_SIZE=$SLURM_JOB_NUM_NODES</span>
<span class="gp"># </span>-----

<span class="go">srun -l torchrun \</span>
<span class="go">    --nproc_per_node=$SLURM_GPUS_PER_NODE\</span>
<span class="go">    --nnodes=$WORLD_SIZE\</span>
<span class="go">    --rdzv_id=$SLURM_JOB_ID\</span>
<span class="go">    --rdzv_backend=c10d\</span>
<span class="go">    --rdzv_endpoint=$RDV_ADDR\</span>
<span class="go">    training_script.py</span>
</pre></div>
</div>
<p>Você pode encontrar abaixo um esboço de um script do PyTorch sobre como um treinador multi-nó pode ser elaborado.</p>
<div class="highlight-python notranslate" id="training-script-outline-for-multi-node-training"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chk_path</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="o">...</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device_id</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span>

    <span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chk_path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="c1"># ...</span>

    <span class="k">def</span> <span class="nf">should_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Note: only one worker saves its weights</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">chk_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Save your states here</span>
        <span class="c1"># Note: you should save the weights of self.model not ddp_model</span>
        <span class="c1"># ...</span>

    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;RANK&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_rank</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Global rank should be set (Only Rank 0 can save checkpoints)&#39;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Local rank should be set&#39;</span>

        <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;gloo|nccl&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sync_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">resuming</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">resuming</span><span class="p">:</span>
            <span class="c1"># in the case of resuming all workers need to load the same checkpoint</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">()</span>

            <span class="c1"># Wait for everybody to finish loading the checkpoint</span>
            <span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
            <span class="k">return</span>

        <span class="c1"># Make sure all workers have the same initial weights</span>
        <span class="c1"># This makes the leader save his weights</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">should_checkpoint</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

        <span class="c1"># All workers wait for the leader to finish</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>

        <span class="c1"># All followers load the leader&#39;s weights</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">should_checkpoint</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">()</span>

        <span class="c1"># Leader waits for the follower to load the weights</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">ElasticDistributedSampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
            <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">train_loader</span>

    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Your batch processing step here</span>
        <span class="c1"># ...</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync_weights</span><span class="p">()</span>

        <span class="n">ddp_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">device_id</span><span class="p">],</span>
            <span class="n">output_device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_id</span>
        <span class="p">)</span>

        <span class="n">loader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataloader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">should_checkpoint</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">tainer</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>“Para contornar o GIL (Bloqueio Global do Interpretador) do Python,
o PyTorch cria um processo para cada GPU. No exemplo acima, isso
significa que pelo menos 12 processos são criados, pelo menos 4 em cada nó.”</p>
</div>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/cin-logo.png" alt="Logo"/>
            </a></p>
  <div>
    <h3><a href="../index.html">Tabela de Conteúdo</a></h3>
    <ul>
<li><a class="reference internal" href="#">Guia do usuário</a><ul>
<li><a class="reference internal" href="#executando-o-seu-codigo">Executando o seu código</a><ul>
<li><a class="reference internal" href="#guia-de-comandos-slurm">Guia de comandos SLURM</a><ul>
<li><a class="reference internal" href="#uso-basico">Uso básico</a></li>
<li><a class="reference internal" href="#enviando-trabalhos">Enviando trabalhos</a><ul>
<li><a class="reference internal" href="#trabalho-em-lote">Trabalho em lote</a></li>
<li><a class="reference internal" href="#job-interativo">Job interativo</a></li>
</ul>
</li>
<li><a class="reference internal" href="#argumentos-de-submissao-de-tarefas">Argumentos de submissão de tarefas</a></li>
<li><a class="reference internal" href="#verificando-job-status">verificando job status</a></li>
<li><a class="reference internal" href="#removendo-um-job">Removendo um job</a></li>
</ul>
</li>
<li><a class="reference internal" href="#particionamento">Particionamento</a></li>
</ul>
</li>
<li><a class="reference internal" href="#preocupacoes-e-solucoes-de-portabilidade">Preocupações e soluções de portabilidade</a><ul>
<li><a class="reference internal" href="#gerenciando-seus-ambientes">Gerenciando seus ambientes</a></li>
<li><a class="reference internal" href="#ambientes-virtuais">Ambientes virtuais</a><ul>
<li><a class="reference internal" href="#pip-virtualenv">Pip/Virtualenv</a></li>
<li><a class="reference internal" href="#conda">Conda</a></li>
</ul>
</li>
<li><a class="reference internal" href="#usando-modulos">Usando módulos</a></li>
<li><a class="reference internal" href="#no-uso-de-conteineres">No uso de contêineres</a></li>
</ul>
</li>
<li><a class="reference internal" href="#singularity">Singularity</a><ul>
<li><a class="reference internal" href="#visao-geral">Visão Geral</a><ul>
<li><a class="reference internal" href="#o-que-e-singularidade">O que é singularidade</a></li>
<li><a class="reference internal" href="#links-para-documentacao-oficial">Links para documentação oficial</a></li>
<li><a class="reference internal" href="#visao-gerald-dos-passos-usados-na-pratica">Visão gerald dos passos usados na prática</a></li>
<li><a class="reference internal" href="#nao-nao-no-macos">Não, não no MacOS</a></li>
<li><a class="reference internal" href="#onde-construir-imagens">Onde construir imagens</a></li>
</ul>
</li>
<li><a class="reference internal" href="#construindo-os-containers">Construindo os containers</a><ul>
<li><a class="reference internal" href="#primeira-maneira-construir-e-usar-um-sandbox">Primeira maneira: construir e usar um sandbox</a><ul>
<li><a class="reference internal" href="#baixando-containers-da-web">Baixando containers da web.</a></li>
<li><a class="reference internal" href="#como-adicionar-ou-instalar-coisas-em-um-container">Como adicionar ou instalar coisas em um container</a></li>
<li><a class="reference internal" href="#criando-diretorios-uteis">Criando diretórios úteis</a></li>
<li><a class="reference internal" href="#testes">Testes</a></li>
<li><a class="reference internal" href="#criando-uma-nova-imagem-a-partir-do-sandbox">Criando uma nova imagem a partir do sandbox</a></li>
</ul>
</li>
<li><a class="reference internal" href="#segunda-opcao-use-receitas">Segunda opção: Use receitas</a><ul>
<li><a class="reference internal" href="#construir-receita-no-singularity-hub">Construir receita no Singularity Hub</a></li>
<li><a class="reference internal" href="#exemplo-receita-com-openai-gym-mujoco-e-miniworld">Exemplo: Receita com OpenAI gym, MuJoCo e Miniworld</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#usando-conteiners-no-cluster">Usando Conteiners no cluster</a><ul>
<li><a class="reference internal" href="#como-usar-conteiners-no-cluster">Como usar conteiners no cluster</a><ul>
<li><a class="reference internal" href="#exemplo-caso-interativo-srun-salloc">Exemplo: Caso interativo (srun/salloc)</a></li>
<li><a class="reference internal" href="#exemplo-caso-sbatch">Exemplo: caso sbatch</a></li>
<li><a class="reference internal" href="#problema-com-as-bibliotecas-pybullet-e-opengl">Problema com as bibliotecas PyBullet e OpenGL</a></li>
<li><a class="reference internal" href="#apuana-cluster">Apuana cluster</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#compartilhando-dados-com-acls">Compartilhando dados com ACLs</a><ul>
<li><a class="reference internal" href="#visualizando-e-verificando-acls">Visualizando e Verificando ACLs</a></li>
</ul>
</li>
<li><a class="reference internal" href="#nos-multiplos">Nós Múltiplos</a><ul>
<li><a class="reference internal" href="#paralelismo-de-dados">Paralelismo de Dados</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Tópico anterior</h4>
    <p class="topless"><a href="../information.html"
                          title="capítulo anterior">Infraestrutura de computação e políticas</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>Essa Página</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/UserGuide/Userguide.rst.txt"
            rel="nofollow">Exibir Fonte</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Busca rápida</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Ir" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navegação</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="Índice Geral"
             >índice</a></li>
        <li class="right" >
          <a href="../information.html" title="Infraestrutura de computação e políticas"
             >anterior</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">documentação Cluster Cin latest</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Guia do usuário</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2023.
      Criada usando <a href="https://www.sphinx-doc.org/pt_BR/master">Sphinx</a> 6.2.1.
    </div>
  </body>
</html>